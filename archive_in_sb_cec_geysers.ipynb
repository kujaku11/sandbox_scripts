{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive in Sciencebase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from mth5.mth5 import MTH5\n",
    "from mth5.clients.zen import ZenClient\n",
    "from mth5 import read_file\n",
    "\n",
    "from mt_metadata.timeseries import Survey, Station, Run, Electric, Magnetic\n",
    "\n",
    "from mtpy import MT\n",
    "\n",
    "from archive.mt_xml import MTSBXML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths\n",
    "\n",
    "Set the data directory, here I have all stations under one folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_2021 = Path(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\GZ2021\")\n",
    "data_directory_2022 = Path(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\GZ2022\")\n",
    "data_directory_2023 = Path(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\GZ2023\")\n",
    "\n",
    "# Calibration path\n",
    "calibration_path = Path(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\antenna_20190411.cal\")\n",
    "\n",
    "# processed transfer functions\n",
    "edi_path_2021 = Path(\n",
    "    r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\transfer_function_archive\\CEC_Geysers_2021\"\n",
    ")\n",
    "edi_path_2022 = Path(\n",
    "    r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\transfer_function_archive\\CEC_Geysers_2022\"\n",
    ")\n",
    "edi_path_2023 = Path(\n",
    "    r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\transfer_function_archive\\CEC_Geysers_2023\"\n",
    ")\n",
    "\n",
    "# dictionary to key off of for directory paths\n",
    "path_dict = {\n",
    "    2021: {\n",
    "        \"data\": data_directory_2021,\n",
    "        \"edi\": edi_path_2021,\n",
    "        \"df\": pd.read_csv(data_directory_2021.joinpath(\"survey_summary.csv\")),\n",
    "    },\n",
    "    2022: {\n",
    "        \"data\": data_directory_2022,\n",
    "        \"edi\": edi_path_2022,\n",
    "        \"df\": pd.read_csv(data_directory_2022.joinpath(\"survey_summary.csv\")),\n",
    "    },\n",
    "    2023: {\n",
    "        \"data\": data_directory_2023,\n",
    "        \"edi\": edi_path_2023,\n",
    "        \"df\": pd.read_csv(data_directory_2023.joinpath(\"survey_summary.csv\")),\n",
    "    },\n",
    "}\n",
    "\n",
    "# archive path\n",
    "archive_path = data_directory_2021.parent.joinpath(\"archive\")\n",
    "archive_path.mkdir(exist_ok=True)\n",
    "\n",
    "# survey ID\n",
    "survey_id = \"CEC_Geysers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_station_name(name, prefix: str=\"\"):\n",
    "    \"\"\"\n",
    "    change station name to be gz{year}{location}\n",
    "    :param name: DESCRIPTION\n",
    "    :type name: TYPE\n",
    "    :return: DESCRIPTION\n",
    "    :rtype: TYPE\n",
    "\n",
    "    \"\"\"\n",
    "    if name.lower().startswith(\"gz3\"):\n",
    "        return name.replace(\"gz3\", f\"gz{prefix}\")\n",
    "    elif name.startswith(\"3\"):\n",
    "        return name.replace(\"3\", f\"gz{prefix}\", 1)\n",
    "    elif name.lower().startswith(\"gz2\"):\n",
    "        st_number = int(name.replace(\"gz\", \"\")) - 200 + 50\n",
    "        return f\"gz{prefix}{st_number}\"\n",
    "    elif name.startswith(\"2\"):\n",
    "        st_number = int(name) - 200 + 50\n",
    "        return f\"gz{prefix}{st_number}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\cec_survey_summaries.csv\")\n",
    "for row in df.itertuples():\n",
    "    df.loc[row.Index, \"station\"] = change_station_name(row.station, prefix=f\"{row.survey[-2:]}\")\n",
    "df.to_csv(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\cec_survey_summaries_renamed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    df.loc[row.Index, \"survey\"] = row.survey.replace('GZ', \"CEC_Geysers_\")\n",
    "df.to_csv(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\cec_survey_summaries_renamed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\cec_survey_summaries_renamed.csv\")\n",
    "df[\"start\"] = pd.to_datetime(df.start)\n",
    "df[\"end\"] = pd.to_datetime(df.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write shapefile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=4326)\n",
    "gdf = gdf.fillna(\"None\")\n",
    "gdf[['station', 'survey', 'start', 'end', 'latitude', 'longitude',\n",
    "       'elevation', 'instrument_id', 'components', 'dipole_ex', 'dipole_ey',\n",
    "       'hx', 'hy', 'geometry']].to_file(archive_path.joinpath(\"cec_geysers_mt_stations.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mwhere(gdf[gdf\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write metadata XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MTSBXML()\n",
    "x.read_template_xml(r\"c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\CL2021\\archive\\clearlake_2022_metadata.xml\")\n",
    "x.update_from_config(r\"C:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\cec_geysers_mt_xml_configuration.cfg\")\n",
    "x.update_bounding_box(df.longitude.max(), df.longitude.min(), df.latitude.max(), df.latitude.min())\n",
    "x.update_time_period(df.start.min().isoformat(), df.end.max().isoformat())\n",
    "x.update_shp_attributes(df)\n",
    "x.update_metadate()\n",
    "x.save(archive_path.joinpath(\"cec_geysers_repeat_mt_metadata.xml\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GZ2021', 'GZ2022', 'GZ2023'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survey.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_metadata = Survey()\n",
    "survey_metadata.acquired_by.author = (\n",
    "    \"Jared Peacock and Mike Mitchell (U.S. Geological Survey)\"\n",
    ")\n",
    "survey_metadata.citation_dataset.doi = r\"https://doi.org/10.5066/P14BJG2A\"\n",
    "survey_metadata.country = \"USA\"\n",
    "survey_metadata.datum = \"WGS84\"\n",
    "survey_metadata.funding_source.comments = (\n",
    "    \"Project Lead is David Alumbaugh of Lawrence Berkeley National Labs\"\n",
    ")\n",
    "survey_metadata.funding_source.email = \"dlalumbaugh@lbl.gov\"\n",
    "survey_metadata.funding_source.grant_id = \"EPC-19-019\"\n",
    "survey_metadata.funding_source.name = \"California Energy Commission\"\n",
    "survey_metadata.funding_source.organization = \"California Energy Commission\"\n",
    "survey_metadata.funding_source.url = \"https://www.energy.ca.gov/\"\n",
    "survey_metadata.geographic_name = \"The Geysers, northern California\"\n",
    "survey_metadata.name = \"MT Monitoring of the Geysers Geothermal Field\"\n",
    "survey_metadata.project = \"MT Monitoring of the Geysers Geothermal Field\"\n",
    "survey_metadata.project_lead.author = \"Jared Peacock\"\n",
    "survey_metadata.project_lead.email = \"jpeacock@usgs.gov\"\n",
    "survey_metadata.project_lead.organization = \"U.S. Geological Survey\"\n",
    "survey_metadata.release_license = \"CC-BY-4.0\"\n",
    "survey_metadata.summary = (\n",
    "    \"The project is funded by the California Energy Commission to monitor The Geysers\"\n",
    "    \"Geothermal field with repeat MT surveys and continuous passive seismic between \"\n",
    "    \"2021-2023.  The end product is a 4D joint inversion of the seismic and MT data.\"\n",
    "    \"Summaries can be found at:\\n\\t\"\n",
    "    \"Peacock, J. R., Alumbaugh, D., Mitchell, M. A., \"\n",
    "    \"Hartline, C. (2022) Repeat Magnetotelluric Measurements to Monitor the Geysers \"\n",
    "    \"Steam Field in Northern California, Proceedings 47th Workshop on Geothermal \"\n",
    "    \"Reservoir Engineering, Stanford, California, \"\n",
    "    \"https://pangea.stanford.edu/ERE/db/IGAstandard/record_detail.php?id=35437.\"\n",
    "    \"\"\n",
    "    \"\\n\\t\"\n",
    "    \"Peacock, J. R., Alumbaugh, D., Mitchell, M. A., \"\n",
    "    \"Hartline, C. (2023) Repeated Magnetotelluric Measurements at the Geysers, California \"\n",
    "    \"Proceedings 48th Workshop on Geothermal \"\n",
    "    \"Reservoir Engineering, Stanford, California, \"\n",
    "    \"https://pangea.stanford.edu/ERE/db/IGAstandard/record_detail.php?id=35652.\"\n",
    "    \"\\n\\t\"\n",
    "    \"Peacock, J. R., Alumbaugh, D., Mitchell, M. A., \"\n",
    "    \"Hartline, C. (2024) Summary of Annual Repeat Magnetotelluric Surveys of the \"\n",
    "    \"Geysers Geothermal Field Proceedings 49th Workshop on Geothermal \"\n",
    "    \"Reservoir Engineering, Stanford, California, \"\n",
    "    \"https://pangea.stanford.edu/ERE/db/IGAstandard/record_detail.php?id=36417.\"\n",
    "    \"\\n\\t\"\n",
    "    \"Um, E. S., Commer, M., Gritto, R., Peacock, J. R., Alumbaugh, D. L.,  \"\n",
    "    \"Jarpe, S. P., and Hartline, C., (2023), Cooperative joint inversion of \"\n",
    "    \"magnetotelluric and microseismic data for imaging The Geysers geothermal \"\n",
    "    \"field, California, USA, GEOPHYSICS 88: WB45-WB54. \"\n",
    "    \"https://doi.org/10.1190/geo2022-0521.1.\"\n",
    ")\n",
    "survey_metadata.northwest_corner.latitude = 38.867\n",
    "survey_metadata.northwest_corner.longitude = -127.717\n",
    "survey_metadata.southeast_corner.latitude = 38.761\n",
    "survey_metadata.southeast_corner.longitude = -122.887\n",
    "survey_metadata.time_period.start = \"2021-04-05T18:19:58+00:00\"\n",
    "survey_metadata.time_period.end = \"2023-05-08T18:00:00+00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "declination_dict = {2021: 13.46, 2022: 13.37, 2023: 13.39}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gz35'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_metadata = Station()\n",
    "station_metadata.to_dict(single=True, required=False)\n",
    "station_metadata.acquired_by.author = \"Jared Peacock, Mike Mitchell, and David Alumbaugh (LBNL)\"\n",
    "station_metadata.acquired_by.comments = None\n",
    "station_metadata.acquired_by.organization = \"U.S. Geological Survey\"\n",
    "station_metadata.channel_layout = \"L\"\n",
    "station_metadata.comments = None\n",
    "station_metadata.data_type = \"BBMT\"\n",
    "station_metadata.location.declination.comments = \"from https://ngdc.noaa.gov/geomag/calculators/magcalc.shtml#declination\"\n",
    "station_metadata.location.declination.model = \"IGRF\"\n",
    "station_metadata.location.declination.value = 12.5\n",
    "station_metadata.orientation.method = \"compass\"\n",
    "station_metadata.orientation.reference_frame = \"geomagnetic\"\n",
    "station_metadata.provenance.comments = \"Time series converted from Zen format to MTH5\"\n",
    "station_metadata.provenance.software.author = \"Jared Peacock\"\n",
    "station_metadata.provenance.software.name = \"MTH5\"\n",
    "station_metadata.provenance.software.version = \"0.4.9\"\n",
    "station_metadata.provenance.submitter.author = \"Jared Peacock\"\n",
    "station_metadata.provenance.submitter.email = \"jpeacock@usgs\"\n",
    "station_metadata.provenance.submitter.organization = \"U.S. Geological Survey\"\n",
    "station_metadata.location.state = \"California\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metadata = Run()\n",
    "run_metadata.data_logger.firmware.author = \"Zonge International\"\n",
    "run_metadata.data_logger.firmware.name = \"ZEN\"\n",
    "run_metadata.data_logger.firmware.version = \"5357\"\n",
    "run_metadata.data_logger.manufacturer = \"Zonge International\"\n",
    "run_metadata.data_logger.model = \"ZEN\"\n",
    "run_metadata.data_logger.id = \"ZEN046\"\n",
    "run_metadata.data_logger.power_source.comments = \"rechargable lithium batteries\"\n",
    "run_metadata.data_logger.power_source.id = None\n",
    "run_metadata.data_logger.power_source.type = \"Li 30 Amp-hr\"\n",
    "run_metadata.data_logger.power_source.voltage.end = 15.3\n",
    "run_metadata.data_logger.power_source.voltage.start = 17.0\n",
    "run_metadata.data_logger.timing_system.comments = \"internal clock updated by GPS timing\"\n",
    "run_metadata.data_logger.timing_system.drift = 0.0\n",
    "run_metadata.data_logger.timing_system.type = \"GPS lock\"\n",
    "run_metadata.data_logger.timing_system.uncertainty = 0.0\n",
    "run_metadata.data_logger.type = \"MT\"\n",
    "run_metadata.metadata_by.author = \"Jared Peacock\"\n",
    "run_metadata.metadata_by.comments = \"Most pulled from Z3D files, the rest from written field notes.\"\n",
    "run_metadata.metadata_by.organization = \"U.S. Geological Survey\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric Channel Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "electric_metadata = Electric()\n",
    "electric_metadata.negative.manufacturer = \"Borin\"\n",
    "electric_metadata.negative.model = \"Stelth1\"\n",
    "electric_metadata.negative.type = \"Ag-AgCl\"\n",
    "electric_metadata.positive.manufacturer = \"Borin\"\n",
    "electric_metadata.positive.model = \"Stelth1\"\n",
    "electric_metadata.positive.type = \"Ag-AgCl\"\n",
    "electric_metadata.type = \"electric\"\n",
    "electric_metadata.units = \"digital counts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnetic Channel Metadata\n",
    "Already updated from Z3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Station MTH5s\n",
    "\n",
    "1. Loop over each folder in the directory, make sure that it is a station\n",
    "2. Save transfer function \n",
    "3. Move MTH5 to archive directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gz201', 'gz202', 'gz203', 'gz204', 'gz205', 'gz206', 'gz207', 'gz208', 'gz210', 'gz211', 'gz212', 'gz213', 'gz214', 'gz215', 'gz232', 'gz301', 'gz302', 'gz303', 'gz304', 'gz305', 'gz306', 'gz307', 'gz308', 'gz309', 'gz310', 'gz311', 'gz312', 'gz313', 'gz314', 'gz315', 'gz316', 'gz317', 'gz318', 'gz319', 'gz320', 'gz321', 'gz322', 'gz323', 'gz324', 'gz325', 'gz326', 'gz327', 'gz328', 'gz329', 'gz330', 'gz331', 'gz332', 'gz334', 'gz335', 'gz337', 'gz338', 'gz345', 'gz346', 'gz348', 'gz349', 'gz350']\n"
     ]
    }
   ],
   "source": [
    "station_list = [\n",
    "    ss.name\n",
    "    for ss in data_directory_2021.iterdir()\n",
    "    if ss.is_dir() and ss.name.startswith(\"gz\")\n",
    "]\n",
    "print(station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instrument_id(station, df):\n",
    "    \"\"\"\n",
    "    Get instrument ID from survey summary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    station : _type_\n",
    "        _description_\n",
    "    year : _type_\n",
    "        _description_\n",
    "    df : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "\n",
    "    if station in df.station.to_list():\n",
    "        station = station\n",
    "    elif f\"gz{station}\" in df.station.to_list():\n",
    "        station = f\"gz{station}\"\n",
    "    elif station.replace(\"gz\", \"\") in df.station.to_list():\n",
    "        station = station.replace(\"gz\", \"\")\n",
    "    elif int(station.replace(\"gz\", \"\")) in df.station.to_list():\n",
    "        station = int(station.replace(\"gz\", \"\"))\n",
    "    else:\n",
    "        logger.error(f\"Could not find station {station} in data frame\")\n",
    "        return None\n",
    "    return df[df.station == station].instrument_id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25:04:15T16:20:37 | INFO | line:677 |mth5.mth5 | _initialize_file | Initialized MTH5 0.2.0 file c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\gz57.h5 in mode a\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:20:45 | WARNING | line:910 |mth5.io.zen.zen | read_z3d | GPS stamps are not 1 second apart for file gz207_20210407_011018_256_HY.Z3D.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:20:45 | WARNING | line:914 |mth5.io.zen.zen | read_z3d | Time block between stamps was not the sample rate for file gz207_20210407_011018_256_HY.Z3D\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:20:49 | WARNING | line:910 |mth5.io.zen.zen | read_z3d | GPS stamps are not 1 second apart for file gz207_20210407_011018_256_EY.Z3D.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:20:49 | WARNING | line:914 |mth5.io.zen.zen | read_z3d | Time block between stamps was not the sample rate for file gz207_20210407_011018_256_EY.Z3D\u001b[0m\n",
      "\u001b[1m25:04:15T16:20:57 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2021-04-07T07:09:43.998047000\u001b[0m\n",
      "\u001b[1m25:04:15T16:21:08 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2021-04-07T13:09:43.998047000\u001b[0m\n",
      "\u001b[1m25:04:15T16:21:13 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2021-04-07T16:26:10.996094000\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:16 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T00:59:43+00:00 does not match metadata end 2021-04-07T00:59:43.968750+00:00 updating metatdata value to 2021-04-07T00:59:43+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:16 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.9999991232844.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:16 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T01:09:43+00:00 does not match metadata end 2021-04-07T01:09:43.998047+00:00 updating metatdata value to 2021-04-07T01:09:43+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:17 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T06:59:43+00:00 does not match metadata end 2021-04-07T06:59:43.968750+00:00 updating metatdata value to 2021-04-07T06:59:43+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:17 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.9999991232844.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:17 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T07:09:43+00:00 does not match metadata end 2021-04-07T07:09:43.998047+00:00 updating metatdata value to 2021-04-07T07:09:43+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:18 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T12:59:43+00:00 does not match metadata end 2021-04-07T12:59:43.968750+00:00 updating metatdata value to 2021-04-07T12:59:43+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:18 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.9999991232844.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:18 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T13:09:43+00:00 does not match metadata end 2021-04-07T13:09:43.998047+00:00 updating metatdata value to 2021-04-07T13:09:43+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:19 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 255.99999999456287.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:19 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T16:26:10+00:00 does not match metadata end 2021-04-07T16:26:10.996094+00:00 updating metatdata value to 2021-04-07T16:26:10+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:19 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2021-04-07T16:26:10+00:00 does not match metadata end 2021-04-07T00:59:43.968750+00:00 updating metatdata value to 2021-04-07T16:26:10+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:19 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:19 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:19 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:19 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[1m25:04:15T16:21:20 | INFO | line:99 |__main__ | <module> | Created c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\gz57.h5\u001b[0m\n",
      "\u001b[1m25:04:15T16:21:20 | INFO | line:112 |__main__ | <module> | Added TF gz2157 to MTH5 gz57.h5\u001b[0m\n",
      "\u001b[1m25:04:15T16:21:28 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2022-04-20T01:09:41.998047000\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:29 | WARNING | line:910 |mth5.io.zen.zen | read_z3d | GPS stamps are not 1 second apart for file Zen046Ch1_20220420-011011_853.z3d.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:29 | WARNING | line:914 |mth5.io.zen.zen | read_z3d | Time block between stamps was not the sample rate for file Zen046Ch1_20220420-011011_853.z3d\u001b[0m\n",
      "\u001b[1m25:04:15T16:21:38 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2022-04-20T07:09:41.998047000\u001b[0m\n",
      "\u001b[1m25:04:15T16:21:49 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2022-04-20T13:09:41.998047000\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:57 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T00:59:41+00:00 does not match metadata end 2022-04-20T00:59:41.968750+00:00 updating metatdata value to 2022-04-20T00:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:57 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:57 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T01:09:41+00:00 does not match metadata end 2022-04-20T01:09:41.998047+00:00 updating metatdata value to 2022-04-20T01:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:58 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T06:59:41+00:00 does not match metadata end 2022-04-20T06:59:41.968750+00:00 updating metatdata value to 2022-04-20T06:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:58 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:58 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T07:09:41+00:00 does not match metadata end 2022-04-20T07:09:41.998047+00:00 updating metatdata value to 2022-04-20T07:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:59 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T12:59:41+00:00 does not match metadata end 2022-04-20T12:59:41.968750+00:00 updating metatdata value to 2022-04-20T12:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:59 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:21:59 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T13:09:41+00:00 does not match metadata end 2022-04-20T13:09:41.998047+00:00 updating metatdata value to 2022-04-20T13:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:00 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 255.99999999597054.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:00 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T17:34:41+00:00 does not match metadata end 2022-04-20T17:34:41.996094+00:00 updating metatdata value to 2022-04-20T17:34:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:00 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2022-04-20T17:34:41+00:00 does not match metadata end 2022-04-20T00:59:41.968750+00:00 updating metatdata value to 2022-04-20T17:34:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:00 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:00 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:00 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:00 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:01 | INFO | line:99 |__main__ | <module> | Created c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\gz57.h5\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:01 | INFO | line:112 |__main__ | <module> | Added TF gz2257 to MTH5 gz57.h5\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:02 | WARNING | line:910 |mth5.io.zen.zen | read_z3d | GPS stamps are not 1 second apart for file gz207_20230428_213517_256_EX.Z3D.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:02 | WARNING | line:914 |mth5.io.zen.zen | read_z3d | Time block between stamps was not the sample rate for file gz207_20230428_213517_256_EX.Z3D\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:07 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2023-04-29T00:59:41.968750000\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:29 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2023-04-29T13:09:41.998047000\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:40 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2023-04-29T19:09:41.998047000\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:44 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T00:59:41+00:00 does not match metadata end 2023-04-29T00:59:41.968750+00:00 updating metatdata value to 2023-04-29T00:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:44 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:44 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T01:09:41+00:00 does not match metadata end 2023-04-29T01:09:41.998047+00:00 updating metatdata value to 2023-04-29T01:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:45 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T06:59:41+00:00 does not match metadata end 2023-04-29T06:59:41.968750+00:00 updating metatdata value to 2023-04-29T06:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:45 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:45 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T07:09:41+00:00 does not match metadata end 2023-04-29T07:09:41.998047+00:00 updating metatdata value to 2023-04-29T07:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:46 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T12:59:41+00:00 does not match metadata end 2023-04-29T12:59:41.968750+00:00 updating metatdata value to 2023-04-29T12:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:47 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:47 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T13:09:41+00:00 does not match metadata end 2023-04-29T13:09:41.998047+00:00 updating metatdata value to 2023-04-29T13:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:47 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T18:59:41+00:00 does not match metadata end 2023-04-29T18:59:41.968750+00:00 updating metatdata value to 2023-04-29T18:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T19:09:41+00:00 does not match metadata end 2023-04-29T19:09:41.998047+00:00 updating metatdata value to 2023-04-29T19:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 255.99999996410537.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T19:39:41+00:00 does not match metadata end 2023-04-29T19:39:41.996094+00:00 updating metatdata value to 2023-04-29T19:39:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-04-29T19:39:41+00:00 does not match metadata end 2023-04-29T00:59:41.968750+00:00 updating metatdata value to 2023-04-29T19:39:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:22:48 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0001 !=  group run.id sr1_0001. Setting to ch.run_metadata.id to sr1_0001\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:49 | INFO | line:99 |__main__ | <module> | Created c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\gz57.h5\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:49 | INFO | line:112 |__main__ | <module> | Added TF gz2357 to MTH5 gz57.h5\u001b[0m\n",
      "\u001b[1m25:04:15T16:22:51 | INFO | line:769 |mth5.mth5 | close_mth5 | Flushing and closing c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\gz57.h5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "survey_id = \"CEC_Geysers\"\n",
    "for station in [\"gz306\"]: #station_list[2:]:\n",
    "    new_station_base = change_station_name(station)\n",
    "    mth5_path = archive_path.joinpath(f\"{new_station_base}.h5\")\n",
    "\n",
    "    # setup initial client\n",
    "    zen_client = ZenClient(\n",
    "        path_dict[2021][\"data\"],\n",
    "        [4096, 256],\n",
    "        save_path=mth5_path.parent,\n",
    "        mth5_filename=mth5_path.name,\n",
    "        calibration_path=calibration_path,\n",
    "    )\n",
    "    try:\n",
    "        with MTH5(**zen_client.h5_kwargs) as m:\n",
    "            m = m.open_mth5(mth5_path)\n",
    "            # loop over year\n",
    "            for year in [2021, 2022, 2023]:\n",
    "                station_path = path_dict[year][\"data\"].joinpath(station)\n",
    "\n",
    "                if station_path.exists():\n",
    "                    # change name to what the transfer functions are\n",
    "\n",
    "\n",
    "                    new_station_name = change_station_name(station, str(year)[2:])\n",
    "                    # change data path in zen client\n",
    "                    zen_client.collection.file_path = station_path\n",
    "                    # get run dictionary\n",
    "                    runs = zen_client.get_run_dict()\n",
    "                    # create survey group\n",
    "                    survey_group = m.add_survey(f\"{survey_id}_{year}\")\n",
    "                    survey_group.metadata.update(survey_metadata)\n",
    "                    survey_group.write_metadata()\n",
    "\n",
    "\n",
    "                    # loop over stations in runs, should only be one run\n",
    "\n",
    "\n",
    "                    for station_id, station_dict in runs.items():\n",
    "                        # add group with new station name\n",
    "                        station_group = survey_group.stations_group.add_station(\n",
    "                            new_station_name\n",
    "                        )\n",
    "                        # update from internal metadata\n",
    "                        station_group.metadata.update(\n",
    "                            zen_client.collection.station_metadata_dict[station_id]\n",
    "                        )\n",
    "                        # update from external metadata\n",
    "                        station_group.metadata.update(station_metadata)\n",
    "                        station_group.metadata.id = new_station_name\n",
    "                        station_group.write_metadata()\n",
    "\n",
    "                        # loop over runs\n",
    "                        run_list = []\n",
    "                        for run_id, run_df in station_dict.items():\n",
    "                            # add run and update metadata\n",
    "                            run_group = station_group.add_run(run_id)\n",
    "                            run_group.metadata.update(run_metadata)\n",
    "                            run_group.metadata.data_logger.id = get_instrument_id(\n",
    "                                station_id, path_dict[year][\"df\"]\n",
    "                            )\n",
    "                            run_group.write_metadata()\n",
    "\n",
    "                            # loop over channels\n",
    "                            for row in run_df.itertuples():\n",
    "                                ch_ts = read_file(\n",
    "                                    row.fn,\n",
    "                                    calibration_fn=row.calibration_fn,\n",
    "                                )\n",
    "                                # update from external metadata if electric channels\n",
    "                                if ch_ts.component in [\"ex\"]:\n",
    "                                    ch_ts.channel_metadata.measurement_azimuth = 0\n",
    "                                elif ch_ts.component in [\"ey\"]:\n",
    "                                    ch_ts.channel_metadata.measurement_azimuth = 90\n",
    "                                elif ch_ts.component in [\"hx\"]:\n",
    "                                    ch_ts.channel_metadata.measurement_azimuth = 0\n",
    "                                elif ch_ts.component in [\"hy\"]:\n",
    "                                    ch_ts.channel_metadata.measurement_azimuth = 90\n",
    "                                if ch_ts.component in [\"ex\", \"ey\"]:\n",
    "                                    ch_ts.channel_metadata.update(electric_metadata)\n",
    "                                run_group.from_channel_ts(ch_ts)\n",
    "                            # update run metadata from channel information\n",
    "                            run_group.update_metadata()\n",
    "                            run_list.append(run_group.to_runts())\n",
    "\n",
    "                        # Combine runs and down sample to 1 second.\n",
    "                        combined_run = run_list[0].merge(run_list[1:], new_sample_rate=1)\n",
    "                        combined_run.run_metadata.id = \"sr1_0001\"\n",
    "                        combined_run_group = station_group.add_run(\"sr1_0001\")\n",
    "                        combined_run_group.metadata.update(run_metadata)\n",
    "                        combined_run_group.metadata.data_logger.id = get_instrument_id(\n",
    "                            station_id, path_dict[year][\"df\"]\n",
    "                        )\n",
    "                        combined_run_group.from_runts(combined_run)\n",
    "                        combined_run_group.update_metadata()\n",
    "                        station_group.update_metadata()\n",
    "                    survey_group.update_metadata()\n",
    "                    \n",
    "                    logger.info(f\"Created {mth5_path}\")\n",
    "\n",
    "                    ### add in transfer function\n",
    "                    edi_fn = path_dict[year][\"edi\"].joinpath(\n",
    "                        f\"USGS-GMEG.{year}.{new_station_name}.edi\"\n",
    "                    )\n",
    "                    if edi_fn.exists():\n",
    "                        mt_obj = MT()\n",
    "                        mt_obj.read(edi_fn)\n",
    "                        mt_obj.survey = f\"{survey_id}_{year}\"\n",
    "                        mt_obj.station = new_station_name\n",
    "                        mt_obj.tf_id = mt_obj.station\n",
    "                        m.add_transfer_function(mt_obj)\n",
    "                        logger.info(f\"Added TF {mt_obj.station} to MTH5 {mth5_path.name}\")\n",
    "                    else:\n",
    "                        logger.warning(\n",
    "                            f\"Could not find transfer function for {station}, aka {new_station_name}\"\n",
    "                        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error with {station} {year}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_station_name_back(name, prefix: str=\"\"):\n",
    "    \"\"\"\n",
    "    change station name to be gz{year}{location}\n",
    "    :param name: DESCRIPTION\n",
    "    :type name: TYPE\n",
    "    :return: DESCRIPTION\n",
    "    :rtype: TYPE\n",
    "\n",
    "    \"\"\"\n",
    "    name = name.replace(f\"gz{prefix}\", \"gz3\")\n",
    "    old_number = int(name.replace(\"gz3\", \"\"))\n",
    "    if  old_number > 50:\n",
    "        name = f\"gz2{old_number-50}\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h5_fn in archive_path.glob(\"*.h5\"):\n",
    "#     with MTH5() as m:\n",
    "#         m = m.open_mth5(h5_fn)\n",
    "#         for run_row in m.run_summary.itertuples():\n",
    "#             run_group = m.from_reference(run_row.run_hdf5_reference)\n",
    "#             year = int(run_row.survey.split(\"_\")[-1])\n",
    "#             old_station = change_station_name_back(run_row.station, str(year)[-2:])\n",
    "#             instrument_id = get_instrument_id(old_station, path_dict[year][\"df\"])\n",
    "#             if instrument_id is not None:\n",
    "#                 run_group.metadata.data_logger.id = instrument_id\n",
    "#                 run_group.write_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25:04:15T16:32:13 | INFO | line:281 |mth5.groups.survey | add_survey | survey CEC_Geysers_2023 already exists, returning existing group.\u001b[0m\n",
      "\u001b[1m25:04:15T16:32:14 | INFO | line:331 |mth5.groups.base | _add_group | StationGroup gz2310 already exists, returning existing group.\u001b[0m\n",
      "\u001b[1m25:04:15T16:32:22 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2023-05-05T19:09:41.998047000\u001b[0m\n",
      "\u001b[1m25:04:15T16:32:36 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2023-05-06T01:09:41.998047000\u001b[0m\n",
      "\u001b[1m25:04:15T16:32:50 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2023-05-06T07:09:41.998047000\u001b[0m\n",
      "\u001b[1m25:04:15T16:33:04 | INFO | line:351 |mth5.timeseries.run_ts | _align_channels | Channels do not have a common end, using latest: 2023-05-06T13:09:41.998047000\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:12 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-05T18:59:41+00:00 does not match metadata end 2023-05-05T18:59:41.968750+00:00 updating metatdata value to 2023-05-05T18:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:12 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:12 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-05T19:09:41+00:00 does not match metadata end 2023-05-05T19:09:41.998047+00:00 updating metatdata value to 2023-05-05T19:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:13 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T00:59:41+00:00 does not match metadata end 2023-05-06T00:59:41.968750+00:00 updating metatdata value to 2023-05-06T00:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:13 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:14 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T01:09:41+00:00 does not match metadata end 2023-05-06T01:09:41.998047+00:00 updating metatdata value to 2023-05-06T01:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:14 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T06:59:41+00:00 does not match metadata end 2023-05-06T06:59:41.968750+00:00 updating metatdata value to 2023-05-06T06:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:15 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:15 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T07:09:41+00:00 does not match metadata end 2023-05-06T07:09:41.998047+00:00 updating metatdata value to 2023-05-06T07:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:15 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T12:59:41+00:00 does not match metadata end 2023-05-06T12:59:41.968750+00:00 updating metatdata value to 2023-05-06T12:59:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:16 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 4095.999999121781.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:16 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T13:09:41+00:00 does not match metadata end 2023-05-06T13:09:41.998047+00:00 updating metatdata value to 2023-05-06T13:09:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:16 | WARNING | line:504 |mth5.timeseries.scipy_filters | resample_poly | New sample rate is not an even number of original sample rate. The ratio is 255.9999999951453.  Use the new dimensions with caution.\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:16 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T16:49:41+00:00 does not match metadata end 2023-05-06T16:49:41.996094+00:00 updating metatdata value to 2023-05-06T16:49:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:16 | WARNING | line:646 |mth5.timeseries.run_ts | validate_metadata | end time of dataset 2023-05-06T16:49:41+00:00 does not match metadata end 2023-05-05T18:59:41.968750+00:00 updating metatdata value to 2023-05-06T16:49:41+00:00\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:17 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0021 !=  group run.id sr1_0002. Setting to ch.run_metadata.id to sr1_0002\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:17 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0021 !=  group run.id sr1_0002. Setting to ch.run_metadata.id to sr1_0002\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:17 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0021 !=  group run.id sr1_0002. Setting to ch.run_metadata.id to sr1_0002\u001b[0m\n",
      "\u001b[33m\u001b[1m25:04:15T16:33:17 | WARNING | line:677 |mth5.groups.run | from_runts | Channel run.id sr256_0021 !=  group run.id sr1_0002. Setting to ch.run_metadata.id to sr1_0002\u001b[0m\n",
      "\u001b[1m25:04:15T16:33:18 | INFO | line:88 |__main__ | <module> | Added TF gz2310 to MTH5 gz10.h5\u001b[0m\n",
      "\u001b[1m25:04:15T16:33:30 | INFO | line:769 |mth5.mth5 | close_mth5 | Flushing and closing c:\\Users\\jpeacock\\OneDrive - DOI\\MTData\\archive\\gz10.h5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "station = \"gz310\"\n",
    "repeat_station = \"gz3102\"\n",
    "new_station_base = change_station_name(station)\n",
    "mth5_path = archive_path.joinpath(f\"{new_station_base}.h5\")\n",
    "\n",
    "# setup initial client\n",
    "zen_client = ZenClient(\n",
    "    path_dict[2023][\"data\"].joinpath(repeat_station),\n",
    "    [4096, 256],\n",
    "    save_path=mth5_path.parent,\n",
    "    mth5_filename=mth5_path.name,\n",
    "    calibration_path=calibration_path,\n",
    ")\n",
    "\n",
    "runs = zen_client.get_run_dict()\n",
    "\n",
    "with MTH5() as m:\n",
    "    m.open_mth5(mth5_path, \"a\")\n",
    "\n",
    "    for station_id, station_dict in runs.items():\n",
    "        new_station_name = change_station_name(station, str(year)[2:])\n",
    "        survey_id = \"CEC_Geysers_2023\"\n",
    "        survey_group = m.add_survey(survey_id)\n",
    "        survey_group.metadata.update(survey_metadata)\n",
    "        survey_group.write_metadata()\n",
    "\n",
    "        station_group = survey_group.stations_group.add_station(new_station_name)\n",
    "        station_group.metadata.update(\n",
    "            zen_client.collection.station_metadata_dict[station_id]\n",
    "        )\n",
    "        station_group.metadata.id = new_station_name\n",
    "        station_group.metadata.update(station_metadata)\n",
    "        station_group.write_metadata()\n",
    "\n",
    "        run_list = []\n",
    "        for run_id, run_df in station_dict.items():\n",
    "            run_parts = run_id.split(\"_\")\n",
    "            run_id = f\"{run_parts[0]}_{int(run_parts[1])+ 20:04}\"\n",
    "            run_group = station_group.add_run(run_id)\n",
    "            run_group.metadata.update(run_metadata)\n",
    "            run_group.metadata.data_logger.id = get_instrument_id(\n",
    "                station_id, path_dict[year][\"df\"]\n",
    "            )\n",
    "            run_group.write_metadata()\n",
    "            for row in run_df.itertuples():\n",
    "                ch_ts = read_file(\n",
    "                    row.fn,\n",
    "                    calibration_fn=row.calibration_fn,\n",
    "                )\n",
    "                # update from external metadata if electric channels\n",
    "                if ch_ts.component in [\"ex\"]:\n",
    "                    ch_ts.channel_metadata.measurement_azimuth = 0\n",
    "                elif ch_ts.component in [\"ey\"]:\n",
    "                    ch_ts.channel_metadata.measurement_azimuth = 90\n",
    "                elif ch_ts.component in [\"hx\"]:\n",
    "                    ch_ts.channel_metadata.measurement_azimuth = 0\n",
    "                elif ch_ts.component in [\"hy\"]:\n",
    "                    ch_ts.channel_metadata.measurement_azimuth = 90\n",
    "                if ch_ts.component in [\"ex\", \"ey\"]:\n",
    "                    ch_ts.channel_metadata.update(electric_metadata)\n",
    "                run_group.from_channel_ts(ch_ts)\n",
    "            run_group.update_metadata()\n",
    "            run_list.append(run_group.to_runts())\n",
    "\n",
    "        # Combine runs and down sample to 1 second.\n",
    "        combined_run = run_list[0].merge(run_list[1:], new_sample_rate=1)\n",
    "        combined_run.run_metadata.id = \"sr1_0002\"\n",
    "        combined_run_group = station_group.add_run(combined_run.run_metadata.id)\n",
    "        combined_run_group.metadata.update(run_metadata)\n",
    "        combined_run_group.metadata.data_logger.id = get_instrument_id(\n",
    "                            station_id, path_dict[year][\"df\"]\n",
    "                        )\n",
    "        combined_run_group.from_runts(combined_run)\n",
    "        combined_run_group.update_metadata()\n",
    "        station_group.update_metadata()\n",
    "    survey_group.update_metadata()\n",
    "\n",
    "    ### add in transfer function\n",
    "    edi_fn = path_dict[year][\"edi\"].joinpath(\n",
    "        f\"USGS-GMEG.{year}.{new_station_name}_repeat.edi\"\n",
    "    )\n",
    "    if edi_fn.exists():\n",
    "        mt_obj = MT()\n",
    "        mt_obj.read(edi_fn)\n",
    "        mt_obj.station = new_station_name\n",
    "        mt_obj.tf_id = mt_obj.tf_id\n",
    "        m.add_transfer_function(mt_obj)\n",
    "        logger.info(f\"Added TF {mt_obj.station} to MTH5 {mth5_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
